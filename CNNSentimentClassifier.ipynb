{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing imdb library from tensorflow\n",
    "imdb = keras.datasets.imdb\n",
    "#Loading data from imdb library to respective variables\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "#Printing Size of Training DataSets\n",
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0 #To indicate padding in a review\n",
    "word_index[\"<START>\"] = 1 #To indicate start of a review\n",
    "word_index[\"<UNK>\"] = 2  #To indicate if a word isn't present in the top 10000 frequent words\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all sentences(reviews) in training dataset of uniform length (256 words)\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "#Making all sentences(reviews) in testing dataset of uniform length (256 words)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000  #Number of most frequent words kept in the embedding vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 256, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 84, 100)           50100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 84, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 13, 100)           50100     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 100)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 6, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2, 100)            10100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 100)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2, 100)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,130,501\n",
      "Trainable params: 1,130,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size,100,input_length=256)) #Converting word to equivalent vector while improving vector while still training per epoch\n",
    "model.add(keras.layers.Conv1D(filters=100,kernel_size=5,strides=3,activation='relu')) #Convolutional Layer 1\n",
    "model.add(keras.layers.Dropout(rate=0.5)) #Dropout Layer 1 (To avoid overfitting)\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)) #Pooling Layer 1 (To take out the important data from Convolutional layer 1)\n",
    "model.add(keras.layers.Conv1D(filters=100,kernel_size=5,strides=3,activation='relu')) #Convolutional Layer 2\n",
    "model.add(keras.layers.Dropout(rate=0.5)) #Dropout Layer 2 (To avoid overfitting)\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)) #Pooling Layer 2 (To take out the important data from Convolutional layer 2)\n",
    "model.add(keras.layers.Conv1D(filters=100,kernel_size=1,strides=3,activation='relu')) #Convolutional Layer 3\n",
    "model.add(keras.layers.Dropout(rate=0.5)) #Dropout Layer 3 (To avoid overfitting)\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=1,strides=1)) #Pooling Layer 3 (To take out the important data from Convolutional layer 3)\n",
    "model.add(keras.layers.Flatten()) #Converting to single array of vectors\n",
    "model.add(keras.layers.Dense(100)) #Feeding to dense layer with 100 neurons\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid)) #Feeding to dense layer with 1 neuron\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=True) #Using Scholastic Gradient Descent as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd,loss='binary_crossentropy',metrics=['acc']) #Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validdata = train_data[:10000] #Validation Data\n",
    "traindata = train_data[10000:] #Training Data\n",
    "\n",
    "validlabels = train_labels[:10000] #Validation Labels (Sentiment)\n",
    "trainlabels = train_labels[10000:] #Training Labels (Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "15000/15000 [==============================] - 8s 566us/sample - loss: 0.4265 - acc: 0.8067 - val_loss: 0.4770 - val_acc: 0.7982\n",
      "Epoch 2/500\n",
      "15000/15000 [==============================] - 8s 560us/sample - loss: 0.4247 - acc: 0.8111 - val_loss: 0.4770 - val_acc: 0.7981\n",
      "Epoch 3/500\n",
      "15000/15000 [==============================] - 8s 557us/sample - loss: 0.4288 - acc: 0.8033 - val_loss: 0.4770 - val_acc: 0.7983\n",
      "Epoch 4/500\n",
      "15000/15000 [==============================] - 8s 561us/sample - loss: 0.4306 - acc: 0.8051 - val_loss: 0.4770 - val_acc: 0.7978\n",
      "Epoch 5/500\n",
      "15000/15000 [==============================] - 8s 562us/sample - loss: 0.4273 - acc: 0.8039 - val_loss: 0.4770 - val_acc: 0.7983\n",
      "Epoch 6/500\n",
      "15000/15000 [==============================] - 9s 567us/sample - loss: 0.4236 - acc: 0.8101 - val_loss: 0.4770 - val_acc: 0.7984\n",
      "Epoch 7/500\n",
      "15000/15000 [==============================] - 9s 586us/sample - loss: 0.4270 - acc: 0.8079 - val_loss: 0.4769 - val_acc: 0.7982\n",
      "Epoch 8/500\n",
      "15000/15000 [==============================] - 9s 574us/sample - loss: 0.4295 - acc: 0.8038 - val_loss: 0.4769 - val_acc: 0.7981\n",
      "Epoch 9/500\n",
      "15000/15000 [==============================] - 9s 581us/sample - loss: 0.4294 - acc: 0.8030 - val_loss: 0.4769 - val_acc: 0.7985\n",
      "Epoch 10/500\n",
      "15000/15000 [==============================] - 9s 583us/sample - loss: 0.4267 - acc: 0.8045 - val_loss: 0.4769 - val_acc: 0.7981\n",
      "Epoch 11/500\n",
      "15000/15000 [==============================] - 9s 581us/sample - loss: 0.4251 - acc: 0.8064 - val_loss: 0.4769 - val_acc: 0.7983\n",
      "Epoch 12/500\n",
      "15000/15000 [==============================] - 9s 580us/sample - loss: 0.4292 - acc: 0.8069 - val_loss: 0.4769 - val_acc: 0.7984\n",
      "Epoch 13/500\n",
      "15000/15000 [==============================] - 9s 607us/sample - loss: 0.4304 - acc: 0.8042 - val_loss: 0.4769 - val_acc: 0.7984\n",
      "Epoch 14/500\n",
      "15000/15000 [==============================] - 9s 578us/sample - loss: 0.4259 - acc: 0.8077 - val_loss: 0.4769 - val_acc: 0.7987\n",
      "Epoch 15/500\n",
      "15000/15000 [==============================] - 9s 576us/sample - loss: 0.4269 - acc: 0.8062 - val_loss: 0.4768 - val_acc: 0.7983\n",
      "Epoch 16/500\n",
      "15000/15000 [==============================] - 9s 580us/sample - loss: 0.4275 - acc: 0.8052 - val_loss: 0.4769 - val_acc: 0.7984\n",
      "Epoch 17/500\n",
      "15000/15000 [==============================] - 9s 579us/sample - loss: 0.4287 - acc: 0.8087 - val_loss: 0.4769 - val_acc: 0.7983\n",
      "Epoch 18/500\n",
      "15000/15000 [==============================] - 9s 584us/sample - loss: 0.4281 - acc: 0.8085 - val_loss: 0.4768 - val_acc: 0.7981\n",
      "Epoch 19/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4261 - acc: 0.8070 - val_loss: 0.4768 - val_acc: 0.7986\n",
      "Epoch 20/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4270 - acc: 0.8060 - val_loss: 0.4768 - val_acc: 0.7987\n",
      "Epoch 21/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4278 - acc: 0.8066 - val_loss: 0.4768 - val_acc: 0.7986\n",
      "Epoch 22/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4272 - acc: 0.8075 - val_loss: 0.4768 - val_acc: 0.7981\n",
      "Epoch 23/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4272 - acc: 0.8077 - val_loss: 0.4768 - val_acc: 0.7983\n",
      "Epoch 24/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4280 - acc: 0.8089 - val_loss: 0.4768 - val_acc: 0.7984\n",
      "Epoch 25/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4282 - acc: 0.8059 - val_loss: 0.4768 - val_acc: 0.7978\n",
      "Epoch 26/500\n",
      "15000/15000 [==============================] - 11s 709us/sample - loss: 0.4266 - acc: 0.8072 - val_loss: 0.4767 - val_acc: 0.7986\n",
      "Epoch 27/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4292 - acc: 0.8063 - val_loss: 0.4767 - val_acc: 0.7983\n",
      "Epoch 28/500\n",
      "15000/15000 [==============================] - 11s 751us/sample - loss: 0.4286 - acc: 0.8051 - val_loss: 0.4767 - val_acc: 0.7984\n",
      "Epoch 29/500\n",
      "15000/15000 [==============================] - 12s 780us/sample - loss: 0.4278 - acc: 0.8063 - val_loss: 0.4767 - val_acc: 0.7984\n",
      "Epoch 30/500\n",
      "15000/15000 [==============================] - 12s 790us/sample - loss: 0.4254 - acc: 0.8063 - val_loss: 0.4767 - val_acc: 0.7985\n",
      "Epoch 31/500\n",
      "15000/15000 [==============================] - 12s 809us/sample - loss: 0.4267 - acc: 0.8049 - val_loss: 0.4767 - val_acc: 0.7986\n",
      "Epoch 32/500\n",
      "15000/15000 [==============================] - 11s 749us/sample - loss: 0.4301 - acc: 0.8031 - val_loss: 0.4767 - val_acc: 0.7987\n",
      "Epoch 33/500\n",
      "15000/15000 [==============================] - 11s 730us/sample - loss: 0.4263 - acc: 0.8101 - val_loss: 0.4767 - val_acc: 0.7980\n",
      "Epoch 34/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4262 - acc: 0.8068 - val_loss: 0.4766 - val_acc: 0.7985\n",
      "Epoch 35/500\n",
      "15000/15000 [==============================] - 11s 722us/sample - loss: 0.4272 - acc: 0.8071 - val_loss: 0.4766 - val_acc: 0.7985\n",
      "Epoch 36/500\n",
      "15000/15000 [==============================] - 11s 718us/sample - loss: 0.4276 - acc: 0.8081 - val_loss: 0.4766 - val_acc: 0.7985\n",
      "Epoch 37/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4261 - acc: 0.8087 - val_loss: 0.4766 - val_acc: 0.7986\n",
      "Epoch 38/500\n",
      "15000/15000 [==============================] - 11s 725us/sample - loss: 0.4237 - acc: 0.8083 - val_loss: 0.4766 - val_acc: 0.7986\n",
      "Epoch 39/500\n",
      "15000/15000 [==============================] - 11s 732us/sample - loss: 0.4272 - acc: 0.8094 - val_loss: 0.4766 - val_acc: 0.7992\n",
      "Epoch 40/500\n",
      "15000/15000 [==============================] - 11s 730us/sample - loss: 0.4231 - acc: 0.8111 - val_loss: 0.4766 - val_acc: 0.7986\n",
      "Epoch 41/500\n",
      "15000/15000 [==============================] - 11s 729us/sample - loss: 0.4213 - acc: 0.8125 - val_loss: 0.4765 - val_acc: 0.7986\n",
      "Epoch 42/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4243 - acc: 0.8095 - val_loss: 0.4765 - val_acc: 0.7985\n",
      "Epoch 43/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4283 - acc: 0.8051 - val_loss: 0.4765 - val_acc: 0.7987\n",
      "Epoch 44/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4247 - acc: 0.8078 - val_loss: 0.4765 - val_acc: 0.7986\n",
      "Epoch 45/500\n",
      "15000/15000 [==============================] - 11s 723us/sample - loss: 0.4252 - acc: 0.8059 - val_loss: 0.4765 - val_acc: 0.7985\n",
      "Epoch 46/500\n",
      "15000/15000 [==============================] - 11s 738us/sample - loss: 0.4288 - acc: 0.8083 - val_loss: 0.4765 - val_acc: 0.7984\n",
      "Epoch 47/500\n",
      "15000/15000 [==============================] - 11s 745us/sample - loss: 0.4304 - acc: 0.8034 - val_loss: 0.4765 - val_acc: 0.7983\n",
      "Epoch 48/500\n",
      "15000/15000 [==============================] - 11s 753us/sample - loss: 0.4302 - acc: 0.8033 - val_loss: 0.4765 - val_acc: 0.7985\n",
      "Epoch 49/500\n",
      "15000/15000 [==============================] - 11s 753us/sample - loss: 0.4253 - acc: 0.8090 - val_loss: 0.4765 - val_acc: 0.7987\n",
      "Epoch 50/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4276 - acc: 0.8045 - val_loss: 0.4764 - val_acc: 0.7987\n",
      "Epoch 51/500\n",
      "15000/15000 [==============================] - 11s 751us/sample - loss: 0.4253 - acc: 0.8058 - val_loss: 0.4764 - val_acc: 0.7983\n",
      "Epoch 52/500\n",
      "15000/15000 [==============================] - 12s 770us/sample - loss: 0.4292 - acc: 0.8041 - val_loss: 0.4764 - val_acc: 0.7983\n",
      "Epoch 53/500\n",
      "15000/15000 [==============================] - 11s 760us/sample - loss: 0.4265 - acc: 0.8058 - val_loss: 0.4764 - val_acc: 0.7984\n",
      "Epoch 54/500\n",
      "15000/15000 [==============================] - 11s 758us/sample - loss: 0.4270 - acc: 0.8077 - val_loss: 0.4764 - val_acc: 0.7984\n",
      "Epoch 55/500\n",
      "15000/15000 [==============================] - 11s 756us/sample - loss: 0.4240 - acc: 0.8079 - val_loss: 0.4764 - val_acc: 0.7983\n",
      "Epoch 56/500\n",
      "15000/15000 [==============================] - 11s 750us/sample - loss: 0.4274 - acc: 0.8065 - val_loss: 0.4764 - val_acc: 0.7983\n",
      "Epoch 57/500\n",
      "15000/15000 [==============================] - 11s 757us/sample - loss: 0.4295 - acc: 0.8041 - val_loss: 0.4764 - val_acc: 0.7988\n",
      "Epoch 58/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4282 - acc: 0.8032 - val_loss: 0.4764 - val_acc: 0.7986\n",
      "Epoch 59/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4285 - acc: 0.8061 - val_loss: 0.4764 - val_acc: 0.7987\n",
      "Epoch 60/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4248 - acc: 0.8092 - val_loss: 0.4764 - val_acc: 0.7986\n",
      "Epoch 61/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4299 - acc: 0.8039 - val_loss: 0.4764 - val_acc: 0.7986\n",
      "Epoch 62/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4293 - acc: 0.8091 - val_loss: 0.4764 - val_acc: 0.7985\n",
      "Epoch 63/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4265 - acc: 0.8083 - val_loss: 0.4763 - val_acc: 0.7988\n",
      "Epoch 64/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4268 - acc: 0.8062 - val_loss: 0.4763 - val_acc: 0.7986\n",
      "Epoch 65/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4311 - acc: 0.8041 - val_loss: 0.4763 - val_acc: 0.7984\n",
      "Epoch 66/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4258 - acc: 0.8079 - val_loss: 0.4763 - val_acc: 0.7988\n",
      "Epoch 67/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4225 - acc: 0.8102 - val_loss: 0.4763 - val_acc: 0.7990\n",
      "Epoch 68/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4315 - acc: 0.8066 - val_loss: 0.4763 - val_acc: 0.7986\n",
      "Epoch 69/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4253 - acc: 0.8090 - val_loss: 0.4763 - val_acc: 0.7985\n",
      "Epoch 70/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4267 - acc: 0.8066 - val_loss: 0.4763 - val_acc: 0.7987\n",
      "Epoch 71/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4246 - acc: 0.8103 - val_loss: 0.4763 - val_acc: 0.7984\n",
      "Epoch 72/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4302 - acc: 0.8054 - val_loss: 0.4763 - val_acc: 0.7985\n",
      "Epoch 73/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4247 - acc: 0.8063 - val_loss: 0.4762 - val_acc: 0.7987\n",
      "Epoch 74/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4264 - acc: 0.8117 - val_loss: 0.4762 - val_acc: 0.7983\n",
      "Epoch 75/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4255 - acc: 0.8066 - val_loss: 0.4762 - val_acc: 0.7985\n",
      "Epoch 76/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4236 - acc: 0.8083 - val_loss: 0.4762 - val_acc: 0.7983\n",
      "Epoch 77/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4261 - acc: 0.8107 - val_loss: 0.4762 - val_acc: 0.7985\n",
      "Epoch 78/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4237 - acc: 0.8084 - val_loss: 0.4762 - val_acc: 0.7986\n",
      "Epoch 79/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4248 - acc: 0.8075 - val_loss: 0.4762 - val_acc: 0.7985\n",
      "Epoch 80/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4287 - acc: 0.8023 - val_loss: 0.4761 - val_acc: 0.7987\n",
      "Epoch 81/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4284 - acc: 0.8060 - val_loss: 0.4762 - val_acc: 0.7983\n",
      "Epoch 82/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4289 - acc: 0.8063 - val_loss: 0.4761 - val_acc: 0.7987\n",
      "Epoch 83/500\n",
      "15000/15000 [==============================] - 10s 700us/sample - loss: 0.4297 - acc: 0.8059 - val_loss: 0.4761 - val_acc: 0.7984\n",
      "Epoch 84/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4277 - acc: 0.8056 - val_loss: 0.4761 - val_acc: 0.7987\n",
      "Epoch 85/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4254 - acc: 0.8089 - val_loss: 0.4761 - val_acc: 0.7987\n",
      "Epoch 86/500\n",
      "15000/15000 [==============================] - 11s 713us/sample - loss: 0.4248 - acc: 0.8081 - val_loss: 0.4761 - val_acc: 0.7988\n",
      "Epoch 87/500\n",
      "15000/15000 [==============================] - 11s 707us/sample - loss: 0.4260 - acc: 0.8076 - val_loss: 0.4761 - val_acc: 0.7985\n",
      "Epoch 88/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4254 - acc: 0.8075 - val_loss: 0.4761 - val_acc: 0.7985\n",
      "Epoch 89/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4300 - acc: 0.8051 - val_loss: 0.4761 - val_acc: 0.7985\n",
      "Epoch 90/500\n",
      "15000/15000 [==============================] - 11s 704us/sample - loss: 0.4282 - acc: 0.8070 - val_loss: 0.4760 - val_acc: 0.7986\n",
      "Epoch 91/500\n",
      "15000/15000 [==============================] - 11s 708us/sample - loss: 0.4273 - acc: 0.8085 - val_loss: 0.4760 - val_acc: 0.7986\n",
      "Epoch 92/500\n",
      "15000/15000 [==============================] - 11s 711us/sample - loss: 0.4244 - acc: 0.8071 - val_loss: 0.4760 - val_acc: 0.7986\n",
      "Epoch 93/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4249 - acc: 0.8101 - val_loss: 0.4760 - val_acc: 0.7987\n",
      "Epoch 94/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4268 - acc: 0.8071 - val_loss: 0.4760 - val_acc: 0.7987\n",
      "Epoch 95/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4259 - acc: 0.8081 - val_loss: 0.4760 - val_acc: 0.7985\n",
      "Epoch 96/500\n",
      "15000/15000 [==============================] - 11s 721us/sample - loss: 0.4261 - acc: 0.8060 - val_loss: 0.4760 - val_acc: 0.7982\n",
      "Epoch 97/500\n",
      "15000/15000 [==============================] - 11s 720us/sample - loss: 0.4270 - acc: 0.8062 - val_loss: 0.4760 - val_acc: 0.7982\n",
      "Epoch 98/500\n",
      "15000/15000 [==============================] - 11s 726us/sample - loss: 0.4271 - acc: 0.8053 - val_loss: 0.4760 - val_acc: 0.7983\n",
      "Epoch 99/500\n",
      "15000/15000 [==============================] - 11s 724us/sample - loss: 0.4284 - acc: 0.8041 - val_loss: 0.4759 - val_acc: 0.7987\n",
      "Epoch 100/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4269 - acc: 0.8095 - val_loss: 0.4759 - val_acc: 0.7984\n",
      "Epoch 101/500\n",
      "15000/15000 [==============================] - 11s 725us/sample - loss: 0.4264 - acc: 0.8102 - val_loss: 0.4759 - val_acc: 0.7985\n",
      "Epoch 102/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4304 - acc: 0.8031 - val_loss: 0.4759 - val_acc: 0.7987\n",
      "Epoch 103/500\n",
      "15000/15000 [==============================] - 11s 727us/sample - loss: 0.4267 - acc: 0.8094 - val_loss: 0.4759 - val_acc: 0.7984\n",
      "Epoch 104/500\n",
      "15000/15000 [==============================] - 11s 738us/sample - loss: 0.4240 - acc: 0.8092 - val_loss: 0.4759 - val_acc: 0.7980\n",
      "Epoch 105/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4275 - acc: 0.8054 - val_loss: 0.4759 - val_acc: 0.7987\n",
      "Epoch 106/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4271 - acc: 0.8036 - val_loss: 0.4759 - val_acc: 0.7986\n",
      "Epoch 107/500\n",
      "15000/15000 [==============================] - 11s 744us/sample - loss: 0.4262 - acc: 0.8075 - val_loss: 0.4759 - val_acc: 0.7985\n",
      "Epoch 108/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4266 - acc: 0.8039 - val_loss: 0.4759 - val_acc: 0.7983\n",
      "Epoch 109/500\n",
      "15000/15000 [==============================] - 11s 744us/sample - loss: 0.4220 - acc: 0.8105 - val_loss: 0.4758 - val_acc: 0.7984\n",
      "Epoch 110/500\n",
      "15000/15000 [==============================] - 11s 746us/sample - loss: 0.4309 - acc: 0.8021 - val_loss: 0.4758 - val_acc: 0.7988\n",
      "Epoch 111/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4243 - acc: 0.8082 - val_loss: 0.4758 - val_acc: 0.7987\n",
      "Epoch 112/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4247 - acc: 0.8095 - val_loss: 0.4758 - val_acc: 0.7989\n",
      "Epoch 113/500\n",
      "15000/15000 [==============================] - 12s 802us/sample - loss: 0.4271 - acc: 0.8049 - val_loss: 0.4758 - val_acc: 0.7989\n",
      "Epoch 114/500\n",
      "15000/15000 [==============================] - 11s 758us/sample - loss: 0.4264 - acc: 0.8065 - val_loss: 0.4758 - val_acc: 0.7986\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4221 - acc: 0.8098 - val_loss: 0.4758 - val_acc: 0.7986\n",
      "Epoch 116/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4267 - acc: 0.8086 - val_loss: 0.4758 - val_acc: 0.7986\n",
      "Epoch 117/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4248 - acc: 0.8090 - val_loss: 0.4758 - val_acc: 0.7987\n",
      "Epoch 118/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4218 - acc: 0.8106 - val_loss: 0.4758 - val_acc: 0.7986\n",
      "Epoch 119/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4248 - acc: 0.8119 - val_loss: 0.4757 - val_acc: 0.7986\n",
      "Epoch 120/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4219 - acc: 0.8116 - val_loss: 0.4757 - val_acc: 0.7986\n",
      "Epoch 121/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4215 - acc: 0.8134 - val_loss: 0.4757 - val_acc: 0.7988\n",
      "Epoch 122/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4286 - acc: 0.8059 - val_loss: 0.4757 - val_acc: 0.7987\n",
      "Epoch 123/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4253 - acc: 0.8103 - val_loss: 0.4757 - val_acc: 0.7986\n",
      "Epoch 124/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4258 - acc: 0.8074 - val_loss: 0.4757 - val_acc: 0.7986\n",
      "Epoch 125/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4207 - acc: 0.8105 - val_loss: 0.4757 - val_acc: 0.7983\n",
      "Epoch 126/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4272 - acc: 0.8102 - val_loss: 0.4756 - val_acc: 0.7987\n",
      "Epoch 127/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4232 - acc: 0.8082 - val_loss: 0.4756 - val_acc: 0.7988\n",
      "Epoch 128/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4228 - acc: 0.8097 - val_loss: 0.4756 - val_acc: 0.7985\n",
      "Epoch 129/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4238 - acc: 0.8081 - val_loss: 0.4756 - val_acc: 0.7985\n",
      "Epoch 130/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4260 - acc: 0.8073 - val_loss: 0.4756 - val_acc: 0.7985\n",
      "Epoch 131/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4271 - acc: 0.8097 - val_loss: 0.4756 - val_acc: 0.7986\n",
      "Epoch 132/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4237 - acc: 0.8096 - val_loss: 0.4755 - val_acc: 0.7988\n",
      "Epoch 133/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4228 - acc: 0.8090 - val_loss: 0.4755 - val_acc: 0.7988\n",
      "Epoch 134/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4275 - acc: 0.8047 - val_loss: 0.4755 - val_acc: 0.7987\n",
      "Epoch 135/500\n",
      "15000/15000 [==============================] - 11s 709us/sample - loss: 0.4250 - acc: 0.8078 - val_loss: 0.4755 - val_acc: 0.7985\n",
      "Epoch 136/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4227 - acc: 0.8098 - val_loss: 0.4755 - val_acc: 0.7987\n",
      "Epoch 137/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4265 - acc: 0.8053 - val_loss: 0.4755 - val_acc: 0.7987\n",
      "Epoch 138/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4230 - acc: 0.8111 - val_loss: 0.4755 - val_acc: 0.7987\n",
      "Epoch 139/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4242 - acc: 0.8074 - val_loss: 0.4755 - val_acc: 0.7987\n",
      "Epoch 140/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4282 - acc: 0.8083 - val_loss: 0.4755 - val_acc: 0.7986\n",
      "Epoch 141/500\n",
      "15000/15000 [==============================] - 11s 713us/sample - loss: 0.4232 - acc: 0.8120 - val_loss: 0.4755 - val_acc: 0.7988\n",
      "Epoch 142/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4282 - acc: 0.8048 - val_loss: 0.4755 - val_acc: 0.7985\n",
      "Epoch 143/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4280 - acc: 0.8077 - val_loss: 0.4755 - val_acc: 0.7985\n",
      "Epoch 144/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4227 - acc: 0.8126 - val_loss: 0.4754 - val_acc: 0.7987\n",
      "Epoch 145/500\n",
      "15000/15000 [==============================] - 11s 707us/sample - loss: 0.4234 - acc: 0.8123 - val_loss: 0.4754 - val_acc: 0.7990\n",
      "Epoch 146/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4263 - acc: 0.8087 - val_loss: 0.4754 - val_acc: 0.7987\n",
      "Epoch 147/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4230 - acc: 0.8093 - val_loss: 0.4754 - val_acc: 0.7990\n",
      "Epoch 148/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4225 - acc: 0.8112 - val_loss: 0.4754 - val_acc: 0.7987\n",
      "Epoch 149/500\n",
      "15000/15000 [==============================] - 11s 708us/sample - loss: 0.4294 - acc: 0.8084 - val_loss: 0.4754 - val_acc: 0.7989\n",
      "Epoch 150/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4278 - acc: 0.8053 - val_loss: 0.4754 - val_acc: 0.7990\n",
      "Epoch 151/500\n",
      "15000/15000 [==============================] - 11s 713us/sample - loss: 0.4259 - acc: 0.8071 - val_loss: 0.4754 - val_acc: 0.7987\n",
      "Epoch 152/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4245 - acc: 0.8101 - val_loss: 0.4753 - val_acc: 0.7987\n",
      "Epoch 153/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4258 - acc: 0.8087 - val_loss: 0.4754 - val_acc: 0.7990\n",
      "Epoch 154/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4250 - acc: 0.8063 - val_loss: 0.4754 - val_acc: 0.7987\n",
      "Epoch 155/500\n",
      "15000/15000 [==============================] - 11s 730us/sample - loss: 0.4242 - acc: 0.8085 - val_loss: 0.4753 - val_acc: 0.7987\n",
      "Epoch 156/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4273 - acc: 0.8033 - val_loss: 0.4753 - val_acc: 0.7986\n",
      "Epoch 157/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4276 - acc: 0.8045 - val_loss: 0.4753 - val_acc: 0.7987\n",
      "Epoch 158/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4264 - acc: 0.8077 - val_loss: 0.4753 - val_acc: 0.7991\n",
      "Epoch 159/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4307 - acc: 0.8041 - val_loss: 0.4753 - val_acc: 0.7989\n",
      "Epoch 160/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4212 - acc: 0.8109 - val_loss: 0.4753 - val_acc: 0.7987\n",
      "Epoch 161/500\n",
      "15000/15000 [==============================] - 11s 741us/sample - loss: 0.4283 - acc: 0.8028 - val_loss: 0.4752 - val_acc: 0.7987\n",
      "Epoch 162/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4266 - acc: 0.8083 - val_loss: 0.4752 - val_acc: 0.7986\n",
      "Epoch 163/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4243 - acc: 0.8110 - val_loss: 0.4752 - val_acc: 0.7988\n",
      "Epoch 164/500\n",
      "15000/15000 [==============================] - 11s 741us/sample - loss: 0.4251 - acc: 0.8049 - val_loss: 0.4752 - val_acc: 0.7990\n",
      "Epoch 165/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4284 - acc: 0.8041 - val_loss: 0.4752 - val_acc: 0.7986\n",
      "Epoch 166/500\n",
      "15000/15000 [==============================] - 11s 744us/sample - loss: 0.4265 - acc: 0.8029 - val_loss: 0.4752 - val_acc: 0.7987\n",
      "Epoch 167/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4241 - acc: 0.8059 - val_loss: 0.4752 - val_acc: 0.7988\n",
      "Epoch 168/500\n",
      "15000/15000 [==============================] - 11s 748us/sample - loss: 0.4226 - acc: 0.8078 - val_loss: 0.4752 - val_acc: 0.7989\n",
      "Epoch 169/500\n",
      "15000/15000 [==============================] - 11s 760us/sample - loss: 0.4257 - acc: 0.8075 - val_loss: 0.4752 - val_acc: 0.7988\n",
      "Epoch 170/500\n",
      "15000/15000 [==============================] - 11s 745us/sample - loss: 0.4238 - acc: 0.8090 - val_loss: 0.4751 - val_acc: 0.7986\n",
      "Epoch 171/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4297 - acc: 0.8024 - val_loss: 0.4751 - val_acc: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "15000/15000 [==============================] - 10s 679us/sample - loss: 0.4250 - acc: 0.8077 - val_loss: 0.4751 - val_acc: 0.7986\n",
      "Epoch 173/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4236 - acc: 0.8116 - val_loss: 0.4751 - val_acc: 0.7991\n",
      "Epoch 174/500\n",
      "15000/15000 [==============================] - 10s 678us/sample - loss: 0.4270 - acc: 0.8053 - val_loss: 0.4751 - val_acc: 0.7990\n",
      "Epoch 175/500\n",
      "15000/15000 [==============================] - 10s 677us/sample - loss: 0.4259 - acc: 0.8078 - val_loss: 0.4751 - val_acc: 0.7990\n",
      "Epoch 176/500\n",
      "15000/15000 [==============================] - 10s 678us/sample - loss: 0.4253 - acc: 0.8059 - val_loss: 0.4751 - val_acc: 0.7991\n",
      "Epoch 177/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4218 - acc: 0.8080 - val_loss: 0.4751 - val_acc: 0.7989\n",
      "Epoch 178/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4278 - acc: 0.8077 - val_loss: 0.4750 - val_acc: 0.7986\n",
      "Epoch 179/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4222 - acc: 0.8096 - val_loss: 0.4750 - val_acc: 0.7987\n",
      "Epoch 180/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4265 - acc: 0.8068 - val_loss: 0.4750 - val_acc: 0.7988\n",
      "Epoch 181/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4243 - acc: 0.8097 - val_loss: 0.4750 - val_acc: 0.7985\n",
      "Epoch 182/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4231 - acc: 0.8085 - val_loss: 0.4750 - val_acc: 0.7989\n",
      "Epoch 183/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4255 - acc: 0.8094 - val_loss: 0.4750 - val_acc: 0.7988\n",
      "Epoch 184/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4218 - acc: 0.8093 - val_loss: 0.4750 - val_acc: 0.7990\n",
      "Epoch 185/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4245 - acc: 0.8079 - val_loss: 0.4750 - val_acc: 0.7990\n",
      "Epoch 186/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4221 - acc: 0.8103 - val_loss: 0.4750 - val_acc: 0.7988\n",
      "Epoch 187/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4221 - acc: 0.8117 - val_loss: 0.4749 - val_acc: 0.7988\n",
      "Epoch 188/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4271 - acc: 0.8078 - val_loss: 0.4749 - val_acc: 0.7988\n",
      "Epoch 189/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4260 - acc: 0.8063 - val_loss: 0.4749 - val_acc: 0.7990\n",
      "Epoch 190/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4233 - acc: 0.8107 - val_loss: 0.4749 - val_acc: 0.7989\n",
      "Epoch 191/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4268 - acc: 0.8078 - val_loss: 0.4749 - val_acc: 0.7990s - loss: 0.4269 - ac\n",
      "Epoch 192/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4261 - acc: 0.8087 - val_loss: 0.4749 - val_acc: 0.7990\n",
      "Epoch 193/500\n",
      "15000/15000 [==============================] - 11s 704us/sample - loss: 0.4249 - acc: 0.8069 - val_loss: 0.4749 - val_acc: 0.7989\n",
      "Epoch 194/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4240 - acc: 0.8079 - val_loss: 0.4749 - val_acc: 0.7992\n",
      "Epoch 195/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4267 - acc: 0.8090 - val_loss: 0.4749 - val_acc: 0.7989\n",
      "Epoch 196/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4251 - acc: 0.8107 - val_loss: 0.4749 - val_acc: 0.7988\n",
      "Epoch 197/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4244 - acc: 0.8082 - val_loss: 0.4749 - val_acc: 0.7988\n",
      "Epoch 198/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4242 - acc: 0.8086 - val_loss: 0.4748 - val_acc: 0.7988\n",
      "Epoch 199/500\n",
      "15000/15000 [==============================] - 11s 753us/sample - loss: 0.4209 - acc: 0.8096 - val_loss: 0.4748 - val_acc: 0.7989\n",
      "Epoch 200/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4235 - acc: 0.8075 - val_loss: 0.4748 - val_acc: 0.7988\n",
      "Epoch 201/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4226 - acc: 0.8109 - val_loss: 0.4748 - val_acc: 0.7988\n",
      "Epoch 202/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4230 - acc: 0.8106 - val_loss: 0.4748 - val_acc: 0.7989\n",
      "Epoch 203/500\n",
      "15000/15000 [==============================] - 11s 708us/sample - loss: 0.4230 - acc: 0.8105 - val_loss: 0.4748 - val_acc: 0.7989\n",
      "Epoch 204/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4224 - acc: 0.8134 - val_loss: 0.4748 - val_acc: 0.7988\n",
      "Epoch 205/500\n",
      "15000/15000 [==============================] - 11s 715us/sample - loss: 0.4229 - acc: 0.8081 - val_loss: 0.4748 - val_acc: 0.7988\n",
      "Epoch 206/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4198 - acc: 0.8095 - val_loss: 0.4747 - val_acc: 0.7989\n",
      "Epoch 207/500\n",
      "15000/15000 [==============================] - 11s 710us/sample - loss: 0.4217 - acc: 0.8127 - val_loss: 0.4747 - val_acc: 0.7990\n",
      "Epoch 208/500\n",
      "15000/15000 [==============================] - 11s 711us/sample - loss: 0.4235 - acc: 0.8105 - val_loss: 0.4747 - val_acc: 0.7989\n",
      "Epoch 209/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4226 - acc: 0.8091 - val_loss: 0.4747 - val_acc: 0.7988\n",
      "Epoch 210/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4274 - acc: 0.8081 - val_loss: 0.4747 - val_acc: 0.7986\n",
      "Epoch 211/500\n",
      "15000/15000 [==============================] - 11s 762us/sample - loss: 0.4226 - acc: 0.8114 - val_loss: 0.4747 - val_acc: 0.7988\n",
      "Epoch 212/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4235 - acc: 0.8089 - val_loss: 0.4747 - val_acc: 0.7988\n",
      "Epoch 213/500\n",
      "15000/15000 [==============================] - 11s 729us/sample - loss: 0.4270 - acc: 0.8065 - val_loss: 0.4747 - val_acc: 0.7988\n",
      "Epoch 214/500\n",
      "15000/15000 [==============================] - 11s 729us/sample - loss: 0.4253 - acc: 0.8080 - val_loss: 0.4746 - val_acc: 0.7990\n",
      "Epoch 215/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4243 - acc: 0.8067 - val_loss: 0.4746 - val_acc: 0.7992\n",
      "Epoch 216/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4246 - acc: 0.8088 - val_loss: 0.4746 - val_acc: 0.7990\n",
      "Epoch 217/500\n",
      "15000/15000 [==============================] - 12s 778us/sample - loss: 0.4247 - acc: 0.8085 - val_loss: 0.4746 - val_acc: 0.7988\n",
      "Epoch 218/500\n",
      "15000/15000 [==============================] - 11s 750us/sample - loss: 0.4233 - acc: 0.8088 - val_loss: 0.4746 - val_acc: 0.7989\n",
      "Epoch 219/500\n",
      "15000/15000 [==============================] - 11s 750us/sample - loss: 0.4225 - acc: 0.8095 - val_loss: 0.4746 - val_acc: 0.7990\n",
      "Epoch 220/500\n",
      "15000/15000 [==============================] - 11s 746us/sample - loss: 0.4226 - acc: 0.8069 - val_loss: 0.4746 - val_acc: 0.7992\n",
      "Epoch 221/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4217 - acc: 0.8141 - val_loss: 0.4746 - val_acc: 0.7990\n",
      "Epoch 222/500\n",
      "15000/15000 [==============================] - 11s 750us/sample - loss: 0.4203 - acc: 0.8118 - val_loss: 0.4745 - val_acc: 0.7990\n",
      "Epoch 223/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4256 - acc: 0.8097 - val_loss: 0.4745 - val_acc: 0.7990\n",
      "Epoch 224/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4256 - acc: 0.8063 - val_loss: 0.4745 - val_acc: 0.7987\n",
      "Epoch 225/500\n",
      "15000/15000 [==============================] - 11s 745us/sample - loss: 0.4244 - acc: 0.8060 - val_loss: 0.4745 - val_acc: 0.7990\n",
      "Epoch 226/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4222 - acc: 0.8093 - val_loss: 0.4745 - val_acc: 0.7992\n",
      "Epoch 227/500\n",
      "15000/15000 [==============================] - 11s 749us/sample - loss: 0.4242 - acc: 0.8085 - val_loss: 0.4745 - val_acc: 0.7991\n",
      "Epoch 228/500\n",
      "15000/15000 [==============================] - 11s 748us/sample - loss: 0.4244 - acc: 0.8115 - val_loss: 0.4745 - val_acc: 0.7988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "15000/15000 [==============================] - 10s 674us/sample - loss: 0.4243 - acc: 0.8080 - val_loss: 0.4745 - val_acc: 0.7989\n",
      "Epoch 230/500\n",
      "15000/15000 [==============================] - 10s 674us/sample - loss: 0.4262 - acc: 0.8071 - val_loss: 0.4745 - val_acc: 0.7989\n",
      "Epoch 231/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4259 - acc: 0.8085 - val_loss: 0.4745 - val_acc: 0.7989\n",
      "Epoch 232/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4248 - acc: 0.8083 - val_loss: 0.4744 - val_acc: 0.7990\n",
      "Epoch 233/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4237 - acc: 0.8081 - val_loss: 0.4744 - val_acc: 0.7992\n",
      "Epoch 234/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4243 - acc: 0.8077 - val_loss: 0.4744 - val_acc: 0.7992\n",
      "Epoch 235/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4247 - acc: 0.8102 - val_loss: 0.4744 - val_acc: 0.7995\n",
      "Epoch 236/500\n",
      "15000/15000 [==============================] - 10s 682us/sample - loss: 0.4220 - acc: 0.8109 - val_loss: 0.4744 - val_acc: 0.7991\n",
      "Epoch 237/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4248 - acc: 0.8084 - val_loss: 0.4744 - val_acc: 0.7988\n",
      "Epoch 238/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4219 - acc: 0.8102 - val_loss: 0.4744 - val_acc: 0.7988\n",
      "Epoch 239/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4230 - acc: 0.8090 - val_loss: 0.4744 - val_acc: 0.7989\n",
      "Epoch 240/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4282 - acc: 0.8061 - val_loss: 0.4744 - val_acc: 0.7993\n",
      "Epoch 241/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4234 - acc: 0.8082 - val_loss: 0.4744 - val_acc: 0.7989\n",
      "Epoch 242/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4236 - acc: 0.8069 - val_loss: 0.4744 - val_acc: 0.7988\n",
      "Epoch 243/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4269 - acc: 0.8068 - val_loss: 0.4743 - val_acc: 0.7988\n",
      "Epoch 244/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4242 - acc: 0.8102 - val_loss: 0.4743 - val_acc: 0.7994\n",
      "Epoch 245/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4268 - acc: 0.8047 - val_loss: 0.4743 - val_acc: 0.7992\n",
      "Epoch 246/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4230 - acc: 0.8107 - val_loss: 0.4743 - val_acc: 0.7991\n",
      "Epoch 247/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4240 - acc: 0.8074 - val_loss: 0.4743 - val_acc: 0.7991\n",
      "Epoch 248/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4251 - acc: 0.8090 - val_loss: 0.4743 - val_acc: 0.7992\n",
      "Epoch 249/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4220 - acc: 0.8094 - val_loss: 0.4743 - val_acc: 0.7990\n",
      "Epoch 250/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4245 - acc: 0.8093 - val_loss: 0.4743 - val_acc: 0.7990231 - acc:\n",
      "Epoch 251/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4224 - acc: 0.8100 - val_loss: 0.4743 - val_acc: 0.7990\n",
      "Epoch 252/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4247 - acc: 0.8089 - val_loss: 0.4743 - val_acc: 0.7989\n",
      "Epoch 253/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4242 - acc: 0.8063 - val_loss: 0.4742 - val_acc: 0.7992\n",
      "Epoch 254/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4224 - acc: 0.8128 - val_loss: 0.4742 - val_acc: 0.7992\n",
      "Epoch 255/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4220 - acc: 0.8083 - val_loss: 0.4742 - val_acc: 0.7990\n",
      "Epoch 256/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4230 - acc: 0.8085 - val_loss: 0.4742 - val_acc: 0.7989\n",
      "Epoch 257/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4225 - acc: 0.8099 - val_loss: 0.4742 - val_acc: 0.7991\n",
      "Epoch 258/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4223 - acc: 0.8117 - val_loss: 0.4742 - val_acc: 0.7992\n",
      "Epoch 259/500\n",
      "15000/15000 [==============================] - 11s 704us/sample - loss: 0.4271 - acc: 0.8097 - val_loss: 0.4742 - val_acc: 0.7992\n",
      "Epoch 260/500\n",
      "15000/15000 [==============================] - 11s 707us/sample - loss: 0.4205 - acc: 0.8123 - val_loss: 0.4742 - val_acc: 0.7994\n",
      "Epoch 261/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4222 - acc: 0.8106 - val_loss: 0.4742 - val_acc: 0.7992\n",
      "Epoch 262/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4196 - acc: 0.8137 - val_loss: 0.4741 - val_acc: 0.7990\n",
      "Epoch 263/500\n",
      "15000/15000 [==============================] - 11s 709us/sample - loss: 0.4212 - acc: 0.8101 - val_loss: 0.4741 - val_acc: 0.7992\n",
      "Epoch 264/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4217 - acc: 0.8103 - val_loss: 0.4741 - val_acc: 0.7992\n",
      "Epoch 265/500\n",
      "15000/15000 [==============================] - 11s 715us/sample - loss: 0.4233 - acc: 0.8105 - val_loss: 0.4741 - val_acc: 0.7993\n",
      "Epoch 266/500\n",
      "15000/15000 [==============================] - 11s 720us/sample - loss: 0.4209 - acc: 0.8111 - val_loss: 0.4741 - val_acc: 0.7992\n",
      "Epoch 267/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4235 - acc: 0.8103 - val_loss: 0.4741 - val_acc: 0.7993\n",
      "Epoch 268/500\n",
      "15000/15000 [==============================] - 11s 718us/sample - loss: 0.4256 - acc: 0.8088 - val_loss: 0.4741 - val_acc: 0.7993\n",
      "Epoch 269/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4245 - acc: 0.8090 - val_loss: 0.4740 - val_acc: 0.7994\n",
      "Epoch 270/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4275 - acc: 0.8094 - val_loss: 0.4741 - val_acc: 0.7992\n",
      "Epoch 271/500\n",
      "15000/15000 [==============================] - 11s 721us/sample - loss: 0.4227 - acc: 0.8077 - val_loss: 0.4740 - val_acc: 0.7992\n",
      "Epoch 272/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4247 - acc: 0.8091 - val_loss: 0.4740 - val_acc: 0.7993\n",
      "Epoch 273/500\n",
      "15000/15000 [==============================] - 11s 725us/sample - loss: 0.4219 - acc: 0.8122 - val_loss: 0.4740 - val_acc: 0.7993\n",
      "Epoch 274/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4285 - acc: 0.8047 - val_loss: 0.4740 - val_acc: 0.7994\n",
      "Epoch 275/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4231 - acc: 0.8093 - val_loss: 0.4740 - val_acc: 0.7994\n",
      "Epoch 276/500\n",
      "15000/15000 [==============================] - 11s 729us/sample - loss: 0.4224 - acc: 0.8111 - val_loss: 0.4740 - val_acc: 0.7993\n",
      "Epoch 277/500\n",
      "15000/15000 [==============================] - 11s 735us/sample - loss: 0.4194 - acc: 0.8131 - val_loss: 0.4740 - val_acc: 0.7993\n",
      "Epoch 278/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4253 - acc: 0.8080 - val_loss: 0.4740 - val_acc: 0.7995\n",
      "Epoch 279/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4231 - acc: 0.8109 - val_loss: 0.4740 - val_acc: 0.7994\n",
      "Epoch 280/500\n",
      "15000/15000 [==============================] - 11s 762us/sample - loss: 0.4248 - acc: 0.8095 - val_loss: 0.4739 - val_acc: 0.7995\n",
      "Epoch 281/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4245 - acc: 0.8090 - val_loss: 0.4739 - val_acc: 0.7993\n",
      "Epoch 282/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4239 - acc: 0.8093 - val_loss: 0.4739 - val_acc: 0.7994\n",
      "Epoch 283/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4222 - acc: 0.8104 - val_loss: 0.4739 - val_acc: 0.7996\n",
      "Epoch 284/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4235 - acc: 0.8105 - val_loss: 0.4739 - val_acc: 0.7994\n",
      "Epoch 285/500\n",
      "15000/15000 [==============================] - 11s 759us/sample - loss: 0.4272 - acc: 0.8063 - val_loss: 0.4739 - val_acc: 0.7995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4248 - acc: 0.8071 - val_loss: 0.4739 - val_acc: 0.7989\n",
      "Epoch 287/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4212 - acc: 0.8109 - val_loss: 0.4739 - val_acc: 0.7989\n",
      "Epoch 288/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4227 - acc: 0.8083 - val_loss: 0.4739 - val_acc: 0.7991\n",
      "Epoch 289/500\n",
      "15000/15000 [==============================] - 10s 682us/sample - loss: 0.4198 - acc: 0.8100 - val_loss: 0.4738 - val_acc: 0.7996\n",
      "Epoch 290/500\n",
      "15000/15000 [==============================] - 10s 677us/sample - loss: 0.4228 - acc: 0.8072 - val_loss: 0.4738 - val_acc: 0.7995\n",
      "Epoch 291/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4208 - acc: 0.8084 - val_loss: 0.4738 - val_acc: 0.7996\n",
      "Epoch 292/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4254 - acc: 0.8071 - val_loss: 0.4738 - val_acc: 0.7995\n",
      "Epoch 293/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4256 - acc: 0.8075 - val_loss: 0.4738 - val_acc: 0.7997\n",
      "Epoch 294/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4243 - acc: 0.8089 - val_loss: 0.4738 - val_acc: 0.7990\n",
      "Epoch 295/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4229 - acc: 0.8115 - val_loss: 0.4738 - val_acc: 0.7990\n",
      "Epoch 296/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4227 - acc: 0.8115 - val_loss: 0.4738 - val_acc: 0.7990\n",
      "Epoch 297/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4216 - acc: 0.8077 - val_loss: 0.4738 - val_acc: 0.7987\n",
      "Epoch 298/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4205 - acc: 0.8103 - val_loss: 0.4738 - val_acc: 0.7998\n",
      "Epoch 299/500\n",
      "15000/15000 [==============================] - 10s 682us/sample - loss: 0.4248 - acc: 0.8053 - val_loss: 0.4737 - val_acc: 0.7995\n",
      "Epoch 300/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4172 - acc: 0.8107 - val_loss: 0.4737 - val_acc: 0.7995\n",
      "Epoch 301/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4245 - acc: 0.8069 - val_loss: 0.4737 - val_acc: 0.7992\n",
      "Epoch 302/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4217 - acc: 0.8133 - val_loss: 0.4737 - val_acc: 0.7996\n",
      "Epoch 303/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4256 - acc: 0.8089 - val_loss: 0.4737 - val_acc: 0.7994\n",
      "Epoch 304/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4198 - acc: 0.8114 - val_loss: 0.4737 - val_acc: 0.7988\n",
      "Epoch 305/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4225 - acc: 0.8127 - val_loss: 0.4737 - val_acc: 0.7990\n",
      "Epoch 306/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4240 - acc: 0.8089 - val_loss: 0.4737 - val_acc: 0.7992\n",
      "Epoch 307/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4221 - acc: 0.8094 - val_loss: 0.4737 - val_acc: 0.7992\n",
      "Epoch 308/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4223 - acc: 0.8075 - val_loss: 0.4737 - val_acc: 0.7997\n",
      "Epoch 309/500\n",
      "15000/15000 [==============================] - 10s 688us/sample - loss: 0.4266 - acc: 0.8093 - val_loss: 0.4736 - val_acc: 0.7993\n",
      "Epoch 310/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4231 - acc: 0.8107 - val_loss: 0.4736 - val_acc: 0.7993\n",
      "Epoch 311/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4208 - acc: 0.8110 - val_loss: 0.4736 - val_acc: 0.7994\n",
      "Epoch 312/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4212 - acc: 0.8151 - val_loss: 0.4736 - val_acc: 0.7993\n",
      "Epoch 313/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4245 - acc: 0.8093 - val_loss: 0.4736 - val_acc: 0.7994\n",
      "Epoch 314/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4205 - acc: 0.8113 - val_loss: 0.4736 - val_acc: 0.7996\n",
      "Epoch 315/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4225 - acc: 0.8109 - val_loss: 0.4735 - val_acc: 0.7992\n",
      "Epoch 316/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4217 - acc: 0.8103 - val_loss: 0.4735 - val_acc: 0.7995\n",
      "Epoch 317/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4245 - acc: 0.8071 - val_loss: 0.4735 - val_acc: 0.7995\n",
      "Epoch 318/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4257 - acc: 0.8087 - val_loss: 0.4735 - val_acc: 0.7994\n",
      "Epoch 319/500\n",
      "15000/15000 [==============================] - 11s 721us/sample - loss: 0.4251 - acc: 0.8061 - val_loss: 0.4735 - val_acc: 0.7994\n",
      "Epoch 320/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4249 - acc: 0.8107 - val_loss: 0.4735 - val_acc: 0.7995\n",
      "Epoch 321/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4202 - acc: 0.8097 - val_loss: 0.4735 - val_acc: 0.7993\n",
      "Epoch 322/500\n",
      "15000/15000 [==============================] - 11s 710us/sample - loss: 0.4228 - acc: 0.8095 - val_loss: 0.4735 - val_acc: 0.7995\n",
      "Epoch 323/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4221 - acc: 0.8132 - val_loss: 0.4735 - val_acc: 0.7996\n",
      "Epoch 324/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4232 - acc: 0.8073 - val_loss: 0.4735 - val_acc: 0.7994\n",
      "Epoch 325/500\n",
      "15000/15000 [==============================] - 11s 718us/sample - loss: 0.4234 - acc: 0.8093 - val_loss: 0.4735 - val_acc: 0.7987\n",
      "Epoch 326/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4198 - acc: 0.8120 - val_loss: 0.4734 - val_acc: 0.7994\n",
      "Epoch 327/500\n",
      "15000/15000 [==============================] - 11s 718us/sample - loss: 0.4246 - acc: 0.8056 - val_loss: 0.4734 - val_acc: 0.7993\n",
      "Epoch 328/500\n",
      "15000/15000 [==============================] - 11s 725us/sample - loss: 0.4217 - acc: 0.8125 - val_loss: 0.4734 - val_acc: 0.7989\n",
      "Epoch 329/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4194 - acc: 0.8154 - val_loss: 0.4734 - val_acc: 0.7993\n",
      "Epoch 330/500\n",
      "15000/15000 [==============================] - 11s 727us/sample - loss: 0.4263 - acc: 0.8059 - val_loss: 0.4734 - val_acc: 0.7996\n",
      "Epoch 331/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4244 - acc: 0.8089 - val_loss: 0.4734 - val_acc: 0.7993\n",
      "Epoch 332/500\n",
      "15000/15000 [==============================] - 11s 731us/sample - loss: 0.4210 - acc: 0.8085 - val_loss: 0.4734 - val_acc: 0.7995\n",
      "Epoch 333/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4266 - acc: 0.8090 - val_loss: 0.4734 - val_acc: 0.7993\n",
      "Epoch 334/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4224 - acc: 0.8096 - val_loss: 0.4734 - val_acc: 0.7993\n",
      "Epoch 335/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4212 - acc: 0.8099 - val_loss: 0.4734 - val_acc: 0.7998\n",
      "Epoch 336/500\n",
      "15000/15000 [==============================] - 11s 738us/sample - loss: 0.4233 - acc: 0.8123 - val_loss: 0.4734 - val_acc: 0.7990\n",
      "Epoch 337/500\n",
      "15000/15000 [==============================] - 11s 735us/sample - loss: 0.4258 - acc: 0.8091 - val_loss: 0.4733 - val_acc: 0.7996\n",
      "Epoch 338/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4223 - acc: 0.8095 - val_loss: 0.4733 - val_acc: 0.7994\n",
      "Epoch 339/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4239 - acc: 0.8061 - val_loss: 0.4733 - val_acc: 0.7996\n",
      "Epoch 340/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4222 - acc: 0.8090 - val_loss: 0.4733 - val_acc: 0.7996\n",
      "Epoch 341/500\n",
      "15000/15000 [==============================] - 11s 744us/sample - loss: 0.4236 - acc: 0.8101 - val_loss: 0.4733 - val_acc: 0.7991\n",
      "Epoch 342/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4200 - acc: 0.8095 - val_loss: 0.4733 - val_acc: 0.7990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "15000/15000 [==============================] - 10s 669us/sample - loss: 0.4231 - acc: 0.8092 - val_loss: 0.4733 - val_acc: 0.7992\n",
      "Epoch 344/500\n",
      "15000/15000 [==============================] - 10s 676us/sample - loss: 0.4220 - acc: 0.8099 - val_loss: 0.4733 - val_acc: 0.7993\n",
      "Epoch 345/500\n",
      "15000/15000 [==============================] - 10s 677us/sample - loss: 0.4195 - acc: 0.8115 - val_loss: 0.4733 - val_acc: 0.7996\n",
      "Epoch 346/500\n",
      "15000/15000 [==============================] - 10s 675us/sample - loss: 0.4233 - acc: 0.8073 - val_loss: 0.4732 - val_acc: 0.7994\n",
      "Epoch 347/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4234 - acc: 0.8086 - val_loss: 0.4732 - val_acc: 0.7995\n",
      "Epoch 348/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4233 - acc: 0.8122 - val_loss: 0.4732 - val_acc: 0.7993\n",
      "Epoch 349/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4241 - acc: 0.8078 - val_loss: 0.4732 - val_acc: 0.7991\n",
      "Epoch 350/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4237 - acc: 0.8103 - val_loss: 0.4732 - val_acc: 0.7992\n",
      "Epoch 351/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4228 - acc: 0.8119 - val_loss: 0.4732 - val_acc: 0.7995\n",
      "Epoch 352/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4244 - acc: 0.8087 - val_loss: 0.4732 - val_acc: 0.7991\n",
      "Epoch 353/500\n",
      "15000/15000 [==============================] - 10s 687us/sample - loss: 0.4263 - acc: 0.8113 - val_loss: 0.4732 - val_acc: 0.7998\n",
      "Epoch 354/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4198 - acc: 0.8096 - val_loss: 0.4732 - val_acc: 0.8001\n",
      "Epoch 355/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4252 - acc: 0.8058 - val_loss: 0.4732 - val_acc: 0.8001\n",
      "Epoch 356/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4224 - acc: 0.8099 - val_loss: 0.4732 - val_acc: 0.7996\n",
      "Epoch 357/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4196 - acc: 0.8137 - val_loss: 0.4732 - val_acc: 0.7992\n",
      "Epoch 358/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4203 - acc: 0.8102 - val_loss: 0.4731 - val_acc: 0.7993\n",
      "Epoch 359/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4244 - acc: 0.8100 - val_loss: 0.4731 - val_acc: 0.7995\n",
      "Epoch 360/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4187 - acc: 0.8105 - val_loss: 0.4731 - val_acc: 0.7998\n",
      "Epoch 361/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4236 - acc: 0.8124 - val_loss: 0.4731 - val_acc: 0.7995\n",
      "Epoch 362/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4218 - acc: 0.8146 - val_loss: 0.4731 - val_acc: 0.7993\n",
      "Epoch 363/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4239 - acc: 0.8096 - val_loss: 0.4731 - val_acc: 0.7995\n",
      "Epoch 364/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4221 - acc: 0.8099 - val_loss: 0.4731 - val_acc: 0.7991\n",
      "Epoch 365/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4240 - acc: 0.8067 - val_loss: 0.4731 - val_acc: 0.7993\n",
      "Epoch 366/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4206 - acc: 0.8107 - val_loss: 0.4731 - val_acc: 0.7990\n",
      "Epoch 367/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4220 - acc: 0.8114 - val_loss: 0.4730 - val_acc: 0.7994\n",
      "Epoch 368/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4225 - acc: 0.8122 - val_loss: 0.4730 - val_acc: 0.7996\n",
      "Epoch 369/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4199 - acc: 0.8145 - val_loss: 0.4730 - val_acc: 0.7995\n",
      "Epoch 370/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4239 - acc: 0.8077 - val_loss: 0.4730 - val_acc: 0.7995\n",
      "Epoch 371/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4247 - acc: 0.8093 - val_loss: 0.4730 - val_acc: 0.7993\n",
      "Epoch 372/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4213 - acc: 0.8089 - val_loss: 0.4730 - val_acc: 0.7993\n",
      "Epoch 373/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4226 - acc: 0.8101 - val_loss: 0.4730 - val_acc: 0.7993\n",
      "Epoch 374/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4246 - acc: 0.8081 - val_loss: 0.4730 - val_acc: 0.7996\n",
      "Epoch 375/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4234 - acc: 0.8085 - val_loss: 0.4730 - val_acc: 0.7996 0.4229 - acc: 0.80\n",
      "Epoch 376/500\n",
      "15000/15000 [==============================] - 11s 704us/sample - loss: 0.4232 - acc: 0.8077 - val_loss: 0.4729 - val_acc: 0.7997\n",
      "Epoch 377/500\n",
      "15000/15000 [==============================] - 11s 706us/sample - loss: 0.4226 - acc: 0.8114 - val_loss: 0.4729 - val_acc: 0.7994\n",
      "Epoch 378/500\n",
      "15000/15000 [==============================] - 11s 709us/sample - loss: 0.4253 - acc: 0.8114 - val_loss: 0.4729 - val_acc: 0.8003\n",
      "Epoch 379/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4228 - acc: 0.8087 - val_loss: 0.4729 - val_acc: 0.7994\n",
      "Epoch 380/500\n",
      "15000/15000 [==============================] - 11s 707us/sample - loss: 0.4243 - acc: 0.8048 - val_loss: 0.4729 - val_acc: 0.7993\n",
      "Epoch 381/500\n",
      "15000/15000 [==============================] - 11s 721us/sample - loss: 0.4269 - acc: 0.8057 - val_loss: 0.4729 - val_acc: 0.7995\n",
      "Epoch 382/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4234 - acc: 0.8134 - val_loss: 0.4729 - val_acc: 0.7996\n",
      "Epoch 383/500\n",
      "15000/15000 [==============================] - 11s 710us/sample - loss: 0.4230 - acc: 0.8111 - val_loss: 0.4729 - val_acc: 0.7993\n",
      "Epoch 384/500\n",
      "15000/15000 [==============================] - 11s 720us/sample - loss: 0.4240 - acc: 0.8089 - val_loss: 0.4729 - val_acc: 0.7993\n",
      "Epoch 385/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4219 - acc: 0.8107 - val_loss: 0.4729 - val_acc: 0.7993\n",
      "Epoch 386/500\n",
      "15000/15000 [==============================] - 11s 738us/sample - loss: 0.4236 - acc: 0.8061 - val_loss: 0.4729 - val_acc: 0.7994\n",
      "Epoch 387/500\n",
      "15000/15000 [==============================] - 11s 732us/sample - loss: 0.4237 - acc: 0.8095 - val_loss: 0.4729 - val_acc: 0.7997\n",
      "Epoch 388/500\n",
      "15000/15000 [==============================] - 11s 727us/sample - loss: 0.4240 - acc: 0.8113 - val_loss: 0.4729 - val_acc: 0.7992\n",
      "Epoch 389/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4226 - acc: 0.8085 - val_loss: 0.4729 - val_acc: 0.7997\n",
      "Epoch 390/500\n",
      "15000/15000 [==============================] - 11s 729us/sample - loss: 0.4210 - acc: 0.8093 - val_loss: 0.4729 - val_acc: 0.7992\n",
      "Epoch 391/500\n",
      "15000/15000 [==============================] - 11s 733us/sample - loss: 0.4264 - acc: 0.8099 - val_loss: 0.4728 - val_acc: 0.7992\n",
      "Epoch 392/500\n",
      "15000/15000 [==============================] - 11s 731us/sample - loss: 0.4225 - acc: 0.8067 - val_loss: 0.4728 - val_acc: 0.7995\n",
      "Epoch 393/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4209 - acc: 0.8100 - val_loss: 0.4728 - val_acc: 0.7992\n",
      "Epoch 394/500\n",
      "15000/15000 [==============================] - 11s 736us/sample - loss: 0.4229 - acc: 0.8099 - val_loss: 0.4728 - val_acc: 0.7994\n",
      "Epoch 395/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4200 - acc: 0.8099 - val_loss: 0.4728 - val_acc: 0.7995\n",
      "Epoch 396/500\n",
      "15000/15000 [==============================] - 11s 741us/sample - loss: 0.4212 - acc: 0.8094 - val_loss: 0.4728 - val_acc: 0.7993\n",
      "Epoch 397/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4197 - acc: 0.8111 - val_loss: 0.4728 - val_acc: 0.7992\n",
      "Epoch 398/500\n",
      "15000/15000 [==============================] - 11s 745us/sample - loss: 0.4202 - acc: 0.8095 - val_loss: 0.4728 - val_acc: 0.7999\n",
      "Epoch 399/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4202 - acc: 0.8123 - val_loss: 0.4727 - val_acc: 0.8004\n",
      "Epoch 400/500\n",
      "15000/15000 [==============================] - 10s 675us/sample - loss: 0.4225 - acc: 0.8083 - val_loss: 0.4727 - val_acc: 0.7992\n",
      "Epoch 401/500\n",
      "15000/15000 [==============================] - 10s 677us/sample - loss: 0.4213 - acc: 0.8098 - val_loss: 0.4727 - val_acc: 0.8006\n",
      "Epoch 402/500\n",
      "15000/15000 [==============================] - 10s 675us/sample - loss: 0.4223 - acc: 0.8109 - val_loss: 0.4727 - val_acc: 0.7995\n",
      "Epoch 403/500\n",
      "15000/15000 [==============================] - 10s 680us/sample - loss: 0.4206 - acc: 0.8112 - val_loss: 0.4727 - val_acc: 0.7994\n",
      "Epoch 404/500\n",
      "15000/15000 [==============================] - 10s 676us/sample - loss: 0.4227 - acc: 0.8049 - val_loss: 0.4727 - val_acc: 0.7997\n",
      "Epoch 405/500\n",
      "15000/15000 [==============================] - 10s 681us/sample - loss: 0.4191 - acc: 0.8149 - val_loss: 0.4727 - val_acc: 0.8001\n",
      "Epoch 406/500\n",
      "15000/15000 [==============================] - 10s 682us/sample - loss: 0.4201 - acc: 0.8127 - val_loss: 0.4727 - val_acc: 0.7992\n",
      "Epoch 407/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4227 - acc: 0.8087 - val_loss: 0.4727 - val_acc: 0.7995\n",
      "Epoch 408/500\n",
      "15000/15000 [==============================] - 10s 678us/sample - loss: 0.4220 - acc: 0.8097 - val_loss: 0.4726 - val_acc: 0.7995\n",
      "Epoch 409/500\n",
      "15000/15000 [==============================] - 10s 685us/sample - loss: 0.4217 - acc: 0.8107 - val_loss: 0.4726 - val_acc: 0.7994\n",
      "Epoch 410/500\n",
      "15000/15000 [==============================] - 10s 682us/sample - loss: 0.4205 - acc: 0.8095 - val_loss: 0.4726 - val_acc: 0.7993\n",
      "Epoch 411/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4229 - acc: 0.8115 - val_loss: 0.4726 - val_acc: 0.8002\n",
      "Epoch 412/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4218 - acc: 0.8102 - val_loss: 0.4726 - val_acc: 0.7994\n",
      "Epoch 413/500\n",
      "15000/15000 [==============================] - 10s 683us/sample - loss: 0.4233 - acc: 0.8095 - val_loss: 0.4726 - val_acc: 0.7993\n",
      "Epoch 414/500\n",
      "15000/15000 [==============================] - 10s 686us/sample - loss: 0.4209 - acc: 0.8117 - val_loss: 0.4726 - val_acc: 0.7993\n",
      "Epoch 415/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4211 - acc: 0.8087 - val_loss: 0.4726 - val_acc: 0.7993\n",
      "Epoch 416/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4198 - acc: 0.8116 - val_loss: 0.4726 - val_acc: 0.7995\n",
      "Epoch 417/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4209 - acc: 0.8111 - val_loss: 0.4725 - val_acc: 0.7996\n",
      "Epoch 418/500\n",
      "15000/15000 [==============================] - 10s 694us/sample - loss: 0.4257 - acc: 0.8077 - val_loss: 0.4726 - val_acc: 0.7996\n",
      "Epoch 419/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4188 - acc: 0.8123 - val_loss: 0.4725 - val_acc: 0.7995\n",
      "Epoch 420/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4202 - acc: 0.8130 - val_loss: 0.4725 - val_acc: 0.8004\n",
      "Epoch 421/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4255 - acc: 0.8031 - val_loss: 0.4725 - val_acc: 0.7996\n",
      "Epoch 422/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4189 - acc: 0.8121 - val_loss: 0.4725 - val_acc: 0.7998\n",
      "Epoch 423/500\n",
      "15000/15000 [==============================] - 10s 689us/sample - loss: 0.4190 - acc: 0.8127 - val_loss: 0.4725 - val_acc: 0.7993\n",
      "Epoch 424/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4225 - acc: 0.8102 - val_loss: 0.4725 - val_acc: 0.7995\n",
      "Epoch 425/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4242 - acc: 0.8103 - val_loss: 0.4725 - val_acc: 0.7994\n",
      "Epoch 426/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4230 - acc: 0.8099 - val_loss: 0.4725 - val_acc: 0.7992\n",
      "Epoch 427/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4256 - acc: 0.8065 - val_loss: 0.4724 - val_acc: 0.7995\n",
      "Epoch 428/500\n",
      "15000/15000 [==============================] - 11s 700us/sample - loss: 0.4263 - acc: 0.8100 - val_loss: 0.4724 - val_acc: 0.7995\n",
      "Epoch 429/500\n",
      "15000/15000 [==============================] - 11s 708us/sample - loss: 0.4187 - acc: 0.8115 - val_loss: 0.4724 - val_acc: 0.7996\n",
      "Epoch 430/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4205 - acc: 0.8109 - val_loss: 0.4724 - val_acc: 0.7994\n",
      "Epoch 431/500\n",
      "15000/15000 [==============================] - 11s 709us/sample - loss: 0.4206 - acc: 0.8127 - val_loss: 0.4724 - val_acc: 0.8001\n",
      "Epoch 432/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4202 - acc: 0.8104 - val_loss: 0.4724 - val_acc: 0.7999\n",
      "Epoch 433/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4211 - acc: 0.8109 - val_loss: 0.4724 - val_acc: 0.7995\n",
      "Epoch 434/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4182 - acc: 0.8116 - val_loss: 0.4724 - val_acc: 0.8004\n",
      "Epoch 435/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4231 - acc: 0.8111 - val_loss: 0.4724 - val_acc: 0.8001\n",
      "Epoch 436/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4246 - acc: 0.8074 - val_loss: 0.4723 - val_acc: 0.8002\n",
      "Epoch 437/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4206 - acc: 0.8106 - val_loss: 0.4723 - val_acc: 0.7997\n",
      "Epoch 438/500\n",
      "15000/15000 [==============================] - 11s 720us/sample - loss: 0.4229 - acc: 0.8101 - val_loss: 0.4723 - val_acc: 0.8002\n",
      "Epoch 439/500\n",
      "15000/15000 [==============================] - 11s 716us/sample - loss: 0.4214 - acc: 0.8081 - val_loss: 0.4723 - val_acc: 0.7995\n",
      "Epoch 440/500\n",
      "15000/15000 [==============================] - 11s 721us/sample - loss: 0.4228 - acc: 0.8071 - val_loss: 0.4723 - val_acc: 0.7994\n",
      "Epoch 441/500\n",
      "15000/15000 [==============================] - 11s 726us/sample - loss: 0.4253 - acc: 0.8055 - val_loss: 0.4723 - val_acc: 0.7996\n",
      "Epoch 442/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4227 - acc: 0.8103 - val_loss: 0.4723 - val_acc: 0.7997\n",
      "Epoch 443/500\n",
      "15000/15000 [==============================] - 11s 722us/sample - loss: 0.4208 - acc: 0.8087 - val_loss: 0.4723 - val_acc: 0.8004\n",
      "Epoch 444/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4229 - acc: 0.8081 - val_loss: 0.4723 - val_acc: 0.7998\n",
      "Epoch 445/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4209 - acc: 0.8099 - val_loss: 0.4722 - val_acc: 0.8002\n",
      "Epoch 446/500\n",
      "15000/15000 [==============================] - 13s 873us/sample - loss: 0.4225 - acc: 0.8099 - val_loss: 0.4722 - val_acc: 0.7995\n",
      "Epoch 447/500\n",
      "15000/15000 [==============================] - 11s 748us/sample - loss: 0.4216 - acc: 0.8114 - val_loss: 0.4722 - val_acc: 0.7997\n",
      "Epoch 448/500\n",
      "15000/15000 [==============================] - 11s 745us/sample - loss: 0.4221 - acc: 0.8119 - val_loss: 0.4722 - val_acc: 0.7995\n",
      "Epoch 449/500\n",
      "15000/15000 [==============================] - 11s 742us/sample - loss: 0.4229 - acc: 0.8074 - val_loss: 0.4722 - val_acc: 0.7996\n",
      "Epoch 450/500\n",
      "15000/15000 [==============================] - 11s 743us/sample - loss: 0.4172 - acc: 0.8093 - val_loss: 0.4722 - val_acc: 0.7997\n",
      "Epoch 451/500\n",
      "15000/15000 [==============================] - 11s 746us/sample - loss: 0.4230 - acc: 0.8089 - val_loss: 0.4722 - val_acc: 0.7996\n",
      "Epoch 452/500\n",
      "15000/15000 [==============================] - 11s 759us/sample - loss: 0.4227 - acc: 0.8104 - val_loss: 0.4722 - val_acc: 0.7995\n",
      "Epoch 453/500\n",
      "15000/15000 [==============================] - 11s 754us/sample - loss: 0.4179 - acc: 0.8119 - val_loss: 0.4722 - val_acc: 0.7997\n",
      "Epoch 454/500\n",
      "15000/15000 [==============================] - 11s 757us/sample - loss: 0.4183 - acc: 0.8111 - val_loss: 0.4722 - val_acc: 0.8002\n",
      "Epoch 455/500\n",
      "15000/15000 [==============================] - 11s 750us/sample - loss: 0.4238 - acc: 0.8097 - val_loss: 0.4721 - val_acc: 0.8004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "15000/15000 [==============================] - 10s 671us/sample - loss: 0.4184 - acc: 0.8127 - val_loss: 0.4721 - val_acc: 0.8004\n",
      "Epoch 457/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4215 - acc: 0.8150 - val_loss: 0.4721 - val_acc: 0.8007\n",
      "Epoch 458/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4212 - acc: 0.8113 - val_loss: 0.4721 - val_acc: 0.8002\n",
      "Epoch 459/500\n",
      "15000/15000 [==============================] - 10s 697us/sample - loss: 0.4207 - acc: 0.8107 - val_loss: 0.4721 - val_acc: 0.7997\n",
      "Epoch 460/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4199 - acc: 0.8125 - val_loss: 0.4721 - val_acc: 0.8000\n",
      "Epoch 461/500\n",
      "15000/15000 [==============================] - 11s 704us/sample - loss: 0.4200 - acc: 0.8123 - val_loss: 0.4721 - val_acc: 0.7994\n",
      "Epoch 462/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4219 - acc: 0.8104 - val_loss: 0.4721 - val_acc: 0.7995\n",
      "Epoch 463/500\n",
      "15000/15000 [==============================] - 10s 691us/sample - loss: 0.4211 - acc: 0.8119 - val_loss: 0.4721 - val_acc: 0.7997\n",
      "Epoch 464/500\n",
      "15000/15000 [==============================] - 10s 690us/sample - loss: 0.4213 - acc: 0.8082 - val_loss: 0.4721 - val_acc: 0.7997\n",
      "Epoch 465/500\n",
      "15000/15000 [==============================] - 11s 705us/sample - loss: 0.4217 - acc: 0.8093 - val_loss: 0.4720 - val_acc: 0.8001\n",
      "Epoch 466/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4220 - acc: 0.8091 - val_loss: 0.4720 - val_acc: 0.8002\n",
      "Epoch 467/500\n",
      "15000/15000 [==============================] - 10s 693us/sample - loss: 0.4218 - acc: 0.8109 - val_loss: 0.4720 - val_acc: 0.7998\n",
      "Epoch 468/500\n",
      "15000/15000 [==============================] - 10s 695us/sample - loss: 0.4251 - acc: 0.8104 - val_loss: 0.4720 - val_acc: 0.7995\n",
      "Epoch 469/500\n",
      "15000/15000 [==============================] - 10s 684us/sample - loss: 0.4251 - acc: 0.8069 - val_loss: 0.4720 - val_acc: 0.7995\n",
      "Epoch 470/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4215 - acc: 0.8096 - val_loss: 0.4720 - val_acc: 0.7996\n",
      "Epoch 471/500\n",
      "15000/15000 [==============================] - 10s 692us/sample - loss: 0.4207 - acc: 0.8113 - val_loss: 0.4720 - val_acc: 0.8002\n",
      "Epoch 472/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4218 - acc: 0.8114 - val_loss: 0.4720 - val_acc: 0.8001\n",
      "Epoch 473/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4174 - acc: 0.8143 - val_loss: 0.4720 - val_acc: 0.8005\n",
      "Epoch 474/500\n",
      "15000/15000 [==============================] - 11s 703us/sample - loss: 0.4192 - acc: 0.8157 - val_loss: 0.4720 - val_acc: 0.8001\n",
      "Epoch 475/500\n",
      "15000/15000 [==============================] - 10s 699us/sample - loss: 0.4210 - acc: 0.8083 - val_loss: 0.4719 - val_acc: 0.8002\n",
      "Epoch 476/500\n",
      "15000/15000 [==============================] - 11s 702us/sample - loss: 0.4220 - acc: 0.8085 - val_loss: 0.4719 - val_acc: 0.8000\n",
      "Epoch 477/500\n",
      "15000/15000 [==============================] - 10s 696us/sample - loss: 0.4208 - acc: 0.8122 - val_loss: 0.4719 - val_acc: 0.8004\n",
      "Epoch 478/500\n",
      "15000/15000 [==============================] - 12s 772us/sample - loss: 0.4197 - acc: 0.8073 - val_loss: 0.4719 - val_acc: 0.8003\n",
      "Epoch 479/500\n",
      "15000/15000 [==============================] - 12s 774us/sample - loss: 0.4202 - acc: 0.8091 - val_loss: 0.4719 - val_acc: 0.8001\n",
      "Epoch 480/500\n",
      "15000/15000 [==============================] - 12s 786us/sample - loss: 0.4239 - acc: 0.8075 - val_loss: 0.4719 - val_acc: 0.7995\n",
      "Epoch 481/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4209 - acc: 0.8111 - val_loss: 0.4719 - val_acc: 0.8003\n",
      "Epoch 482/500\n",
      "15000/15000 [==============================] - 10s 698us/sample - loss: 0.4189 - acc: 0.8087 - val_loss: 0.4719 - val_acc: 0.8002\n",
      "Epoch 483/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4237 - acc: 0.8065 - val_loss: 0.4719 - val_acc: 0.7997\n",
      "Epoch 484/500\n",
      "15000/15000 [==============================] - 11s 701us/sample - loss: 0.4223 - acc: 0.8117 - val_loss: 0.4719 - val_acc: 0.8000\n",
      "Epoch 485/500\n",
      "15000/15000 [==============================] - 11s 722us/sample - loss: 0.4210 - acc: 0.8109 - val_loss: 0.4719 - val_acc: 0.7998\n",
      "Epoch 486/500\n",
      "15000/15000 [==============================] - 11s 711us/sample - loss: 0.4197 - acc: 0.8113 - val_loss: 0.4718 - val_acc: 0.8000\n",
      "Epoch 487/500\n",
      "15000/15000 [==============================] - 11s 717us/sample - loss: 0.4235 - acc: 0.8077 - val_loss: 0.4718 - val_acc: 0.8001\n",
      "Epoch 488/500\n",
      "15000/15000 [==============================] - 11s 711us/sample - loss: 0.4201 - acc: 0.8133 - val_loss: 0.4718 - val_acc: 0.8009\n",
      "Epoch 489/500\n",
      "15000/15000 [==============================] - 11s 714us/sample - loss: 0.4247 - acc: 0.8100 - val_loss: 0.4718 - val_acc: 0.8004\n",
      "Epoch 490/500\n",
      "15000/15000 [==============================] - 11s 712us/sample - loss: 0.4202 - acc: 0.8123 - val_loss: 0.4718 - val_acc: 0.8003\n",
      "Epoch 491/500\n",
      "15000/15000 [==============================] - 11s 719us/sample - loss: 0.4202 - acc: 0.8125 - val_loss: 0.4718 - val_acc: 0.8003\n",
      "Epoch 492/500\n",
      "15000/15000 [==============================] - 11s 728us/sample - loss: 0.4228 - acc: 0.8097 - val_loss: 0.4718 - val_acc: 0.8002\n",
      "Epoch 493/500\n",
      "15000/15000 [==============================] - 11s 720us/sample - loss: 0.4220 - acc: 0.8105 - val_loss: 0.4718 - val_acc: 0.8003\n",
      "Epoch 494/500\n",
      "15000/15000 [==============================] - 11s 734us/sample - loss: 0.4201 - acc: 0.8135 - val_loss: 0.4718 - val_acc: 0.8002194 \n",
      "Epoch 495/500\n",
      "15000/15000 [==============================] - 11s 724us/sample - loss: 0.4213 - acc: 0.8121 - val_loss: 0.4718 - val_acc: 0.8002\n",
      "Epoch 496/500\n",
      "15000/15000 [==============================] - 11s 731us/sample - loss: 0.4223 - acc: 0.8079 - val_loss: 0.4717 - val_acc: 0.8000\n",
      "Epoch 497/500\n",
      "15000/15000 [==============================] - 11s 735us/sample - loss: 0.4197 - acc: 0.8121 - val_loss: 0.4717 - val_acc: 0.8008\n",
      "Epoch 498/500\n",
      "15000/15000 [==============================] - 11s 747us/sample - loss: 0.4208 - acc: 0.8101 - val_loss: 0.4717 - val_acc: 0.8003\n",
      "Epoch 499/500\n",
      "15000/15000 [==============================] - 11s 737us/sample - loss: 0.4235 - acc: 0.8123 - val_loss: 0.4717 - val_acc: 0.8001\n",
      "Epoch 500/500\n",
      "15000/15000 [==============================] - 11s 739us/sample - loss: 0.4210 - acc: 0.8095 - val_loss: 0.4717 - val_acc: 0.8006\n"
     ]
    }
   ],
   "source": [
    "#Training model (Total of 7000 epochs)\n",
    "history = model.fit(traindata,\n",
    "                    trainlabels,\n",
    "                    epochs=500,\n",
    "                    batch_size=100,\n",
    "                    validation_data=(validdata, validlabels),\n",
    "                    verbose=1,\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 5s 186us/sample - loss: 0.4734 - acc: 0.7984\n",
      "[0.4734490588951111, 0.79844]\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Model with Test DataSet\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "#Printing Result of Trained Neural Network\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
